# -*- coding: utf-8 -*-
"""Face Recognition with Support Vector Machines

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17K7-6YVdVmw5nn5J5BP_7FCxb7YxDsqK
"""

# Import modules
import warnings, pandas as pd
# Filter warnings
warnings.filterwarnings('ignore')
# Load the Feature dataset into DataFrame.
features_df = pd.read_csv('https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/whitehat-ds-datasets/olivetti_X.csv', header=None)
features_df.head()
# Load the Target dataset into DataFrame.
target_df = pd.read_csv('https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/whitehat-ds-datasets/olivetti_y.csv', header=None)
# Print the number of rows and columns of both the DataFrame
print(features_df.shape)
print(target_df.shape)

# Add `target` column in Feature DataFrame.
features_df['target'] = target_df

# Verify the number of rows and columns in Feature DataFrame
print(features_df.shape)
# Print first five rows
features_df.head()

# Check the distribution of the labels in the target column.
features_df['target'].value_counts()

# Create a Python function to visualise exactly one sample image of a label that exists in the 'df' DataFrame.
import matplotlib.pyplot as plt

# Create the group object of the DataFrame
df_grouped = features_df.groupby('target')

# Define the function to visualise the images
def visualise(label):
  # Get the group for the input label
  pixels = df_grouped.get_group(label)
  # Get the row number of the first instance in the group
  first_row_data = pixels.iloc[0, :-1]
  # Get the data of the row number selected

  # Reshape the data into a 2D array of 64 x 64.
  first_row_data = first_row_data.values.reshape(64, 64)

  # Create the image
  plt.figure(figsize = (5, 5), dpi = 81)
  plt.title(f"Person label: {label}", fontsize = 16)
  plt.imshow(first_row_data, cmap = 'gray')
  plt.show()

# Call the function to create the images.
for i in range(40):
  visualise(i)

  # Split the training and testing data

# Import the module
from sklearn.model_selection import train_test_split
# Create the feature and target variables
x = features_df.iloc[:,:-1]
y = features_df['target']
# Split the feature and target arrays
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)

# Print the shape of all the four variables i.e. 'X_train', 'X_test', 'y_train', and 'y_test'
print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

# Build a logistic regression model using the 'sklearn' module.
from sklearn.svm import SVC

# 1. Create the SVC model and pass 'kernel=linear' as input.
svc_model = SVC(kernel='linear')
# 2. Call the 'fit()' function with 'X_train' and 'y_train' as inputs.
svc_model.fit(x_train, y_train)
# 3. Call the 'score()' function with 'X_train' and 'y_train' as inputs to check the accuracy score of the model.
svc_model.score(x_train, y_train)

# Make predictions on the train dataset by using the 'predict()' function.
train_predictions = svc_model.predict(x_train)
# Print the occurrence of each label computed in the predictions.
print(pd.Series(train_predictions).value_counts())

# Make predictions on the test dataset.
test_predictions = svc_model.predict(x_test)

# Print the occurrence of each label computed in the predictions.
print(pd.Series(test_predictions).value_counts())

# Create the confusion matrix heatmap for the training dataset predictions

# Import the module
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
# Create the training confusion matrix DataFrame
conf_matrix = confusion_matrix(y_train, train_predictions)
# Create the heatmap
plt.figure(figsize=(20,14))
sns.heatmap(conf_matrix, annot=True)
plt.show()

# Print the classification report for the training predictions.
print(classification_report(y_train, train_predictions))

# Create the confusion matrix heatmap for the testing dataset predictions

# Create the testing confusion matrix DataFrame
conf_matrix_test = confusion_matrix(y_train, train_predictions)
# Create the heatmap
plt.figure(figsize=(20,14))
sns.heatmap(conf_matrix_test, annot=True)
plt.show()

# Print the classification report for the testing predictions.
print(classification_report(y_test, test_predictions))